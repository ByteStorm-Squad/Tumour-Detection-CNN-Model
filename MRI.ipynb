{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2de65220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing relevant libraris\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import pathlib as pl\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b5df6b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_class(path):\n",
    "    if(path == 'Datathon-Dataset\\category1_tumor'):\n",
    "        return 0\n",
    "    elif(path == 'Datathon-Dataset\\category2_tumor'):\n",
    "        return 1\n",
    "    elif(path == 'Datathon-Dataset\\category3_tumor'):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b9eba75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# function to create the data set\n",
    "def create_dataset(path):\n",
    "    x,y = [],[]\n",
    "    for subdir in pl.Path(path).iterdir():\n",
    "        if subdir.is_dir():\n",
    "            data_dir = pl.Path(subdir)\n",
    "            file_list = list(data_dir.glob('*.jpg'))\n",
    "            \n",
    "            for file in file_list:\n",
    "                file_path = data_dir.joinpath(file.name)\n",
    "                img = cv2.imread(str(file_path))\n",
    "                resized_img = cv2.resize(img,(150,150))\n",
    "                x.append(resized_img)\n",
    "                y.append(select_class(str(subdir)))\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cea7938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = create_dataset('Datathon-Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "303f2dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(x)\n",
    "Y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e848d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffeling the data set\n",
    "X,Y = shuffle(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "64fad9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.1 ,random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "be3903b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_net = EfficientNetB0(weights = 'imagenet',include_top = False,input_shape = (150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "556aee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficient_net.output\n",
    "model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "model = tf.keras.models.Model(inputs=efficient_net.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2fff0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2c2b624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir = 'logs')\n",
    "checkpoint = ModelCheckpoint(\"effnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n",
    "                              mode='auto',verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d74d0f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.4882 - accuracy: 0.8146\n",
      "Epoch 1: val_accuracy improved from -inf to 0.86254, saving model to effnet.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amila Kasun\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - 242s 3s/step - loss: 0.4882 - accuracy: 0.8146 - val_loss: 0.5287 - val_accuracy: 0.8625 - lr: 0.0010\n",
      "Epoch 2/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1665 - accuracy: 0.9483\n",
      "Epoch 2: val_accuracy did not improve from 0.86254\n",
      "82/82 [==============================] - 221s 3s/step - loss: 0.1665 - accuracy: 0.9483 - val_loss: 0.5421 - val_accuracy: 0.8591 - lr: 0.0010\n",
      "Epoch 3/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.1060 - accuracy: 0.9678\n",
      "Epoch 3: val_accuracy did not improve from 0.86254\n",
      "\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "82/82 [==============================] - 210s 3s/step - loss: 0.1060 - accuracy: 0.9678 - val_loss: 0.8296 - val_accuracy: 0.7973 - lr: 0.0010\n",
      "Epoch 4/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9759\n",
      "Epoch 4: val_accuracy improved from 0.86254 to 0.92096, saving model to effnet.h5\n",
      "82/82 [==============================] - 211s 3s/step - loss: 0.0750 - accuracy: 0.9759 - val_loss: 0.2920 - val_accuracy: 0.9210 - lr: 3.0000e-04\n",
      "Epoch 5/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9931\n",
      "Epoch 5: val_accuracy improved from 0.92096 to 0.94845, saving model to effnet.h5\n",
      "82/82 [==============================] - 210s 3s/step - loss: 0.0244 - accuracy: 0.9931 - val_loss: 0.2173 - val_accuracy: 0.9485 - lr: 3.0000e-04\n",
      "Epoch 6/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9935\n",
      "Epoch 6: val_accuracy did not improve from 0.94845\n",
      "82/82 [==============================] - 220s 3s/step - loss: 0.0203 - accuracy: 0.9935 - val_loss: 0.1914 - val_accuracy: 0.9485 - lr: 3.0000e-04\n",
      "Epoch 7/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0207 - accuracy: 0.9950\n",
      "Epoch 7: val_accuracy improved from 0.94845 to 0.95876, saving model to effnet.h5\n",
      "82/82 [==============================] - 212s 3s/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.1738 - val_accuracy: 0.9588 - lr: 3.0000e-04\n",
      "Epoch 8/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9981\n",
      "Epoch 8: val_accuracy did not improve from 0.95876\n",
      "82/82 [==============================] - 216s 3s/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.1928 - val_accuracy: 0.9588 - lr: 3.0000e-04\n",
      "Epoch 9/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0127 - accuracy: 0.9973\n",
      "Epoch 9: val_accuracy did not improve from 0.95876\n",
      "\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "82/82 [==============================] - 257s 3s/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.2063 - val_accuracy: 0.9588 - lr: 3.0000e-04\n",
      "Epoch 10/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.9992\n",
      "Epoch 10: val_accuracy did not improve from 0.95876\n",
      "82/82 [==============================] - 230s 3s/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.2022 - val_accuracy: 0.9553 - lr: 9.0000e-05\n",
      "Epoch 11/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 11: val_accuracy did not improve from 0.95876\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "82/82 [==============================] - 274s 3s/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.2091 - val_accuracy: 0.9588 - lr: 9.0000e-05\n",
      "Epoch 12/12\n",
      "82/82 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 12: val_accuracy improved from 0.95876 to 0.96220, saving model to effnet.h5\n",
      "82/82 [==============================] - 341s 4s/step - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.1945 - val_accuracy: 0.9622 - lr: 2.7000e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n",
    "                   callbacks=[tensorboard,checkpoint,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "43d3eaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 574ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2f6a6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e07bdc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "21c59a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 2, 0, 0, 0, 2, 2, 3, 1, 1, 0, 0, 2, 2, 2, 1, 3, 0, 2, 2,\n",
       "       2, 1, 3, 1, 0, 2, 3, 1, 0, 2, 2, 3, 3, 3, 1, 0, 1, 1, 2, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2, 1, 0, 3, 1, 0, 0, 1, 0, 2, 0, 1,\n",
       "       3, 2, 0, 3, 1, 0, 2, 3, 2, 1, 0, 2, 0, 3, 1, 3, 0, 1, 2, 3, 3, 0,\n",
       "       2, 0, 1, 0, 1, 1, 0, 1, 3, 2, 1, 2, 0, 1, 3, 0, 1, 0, 2, 2, 1, 1,\n",
       "       2, 3, 2, 0, 2, 1, 3, 2, 1, 1, 3, 1, 1, 0, 2, 0, 1, 0, 2, 1, 0, 2,\n",
       "       2, 3, 1, 1, 1, 0, 1, 1, 2, 1, 2, 2, 2, 0, 0, 1, 3, 2, 2, 1, 0, 1,\n",
       "       2, 2, 1, 2, 2, 0, 1, 2, 2, 3, 0, 2, 2, 0, 2, 2, 2, 3, 3, 1, 0, 1,\n",
       "       3, 1, 1, 0, 2, 1, 3, 2, 1, 1, 3, 0, 2, 0, 2, 3, 2, 2, 2, 1, 2, 2,\n",
       "       0, 3, 1, 3, 0, 1, 1, 0, 0, 3, 3, 2, 2, 1, 0, 3, 0, 2, 1, 1, 3, 2,\n",
       "       1, 0, 1, 0, 2, 0, 0, 0, 2, 1, 3, 2, 2, 0, 2, 1, 3, 2, 0, 2, 0, 0,\n",
       "       0, 1, 0, 3, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 2, 0, 3, 1, 1, 1, 0, 0,\n",
       "       3, 0, 2, 1, 1, 2, 2, 2, 3, 3, 0, 2, 0, 1, 2, 2, 0, 2, 3, 1, 0, 0,\n",
       "       0, 0, 2, 0, 2, 3, 2, 2, 3, 2, 1, 2, 0, 3, 0, 3, 1, 1, 1, 1, 1, 2,\n",
       "       1, 0, 2, 2, 3, 1, 1, 2, 1, 0, 2, 3, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "09873bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 2, 0, 0, 0, 2, 2, 3, 1, 1, 0, 0, 2, 2, 2, 1, 3, 0, 2, 2,\n",
       "       2, 1, 3, 1, 0, 2, 3, 1, 0, 2, 2, 3, 3, 3, 1, 0, 1, 1, 2, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 2, 1, 0, 3, 1, 0, 0, 1, 0, 2, 0, 1,\n",
       "       3, 2, 0, 3, 1, 0, 2, 3, 2, 1, 0, 2, 0, 3, 1, 3, 0, 1, 2, 3, 3, 0,\n",
       "       2, 0, 1, 0, 1, 1, 0, 1, 3, 2, 1, 2, 0, 1, 3, 0, 1, 0, 2, 2, 1, 1,\n",
       "       2, 3, 2, 0, 2, 1, 3, 2, 1, 1, 3, 1, 1, 0, 2, 0, 1, 0, 2, 0, 0, 2,\n",
       "       2, 3, 1, 1, 1, 0, 1, 1, 2, 1, 2, 2, 2, 0, 0, 1, 3, 2, 2, 1, 0, 1,\n",
       "       2, 2, 1, 2, 2, 0, 1, 2, 2, 3, 0, 2, 2, 0, 2, 2, 2, 3, 3, 1, 0, 1,\n",
       "       3, 1, 1, 0, 2, 1, 3, 2, 1, 1, 3, 0, 2, 0, 2, 3, 2, 2, 2, 1, 2, 2,\n",
       "       0, 3, 1, 3, 0, 1, 1, 0, 0, 3, 3, 2, 2, 1, 0, 3, 0, 2, 1, 1, 3, 2,\n",
       "       1, 0, 1, 0, 2, 0, 0, 0, 2, 1, 3, 2, 2, 0, 2, 1, 3, 2, 0, 2, 0, 0,\n",
       "       0, 1, 0, 3, 2, 2, 2, 1, 0, 0, 0, 0, 1, 0, 2, 0, 3, 1, 1, 1, 0, 0,\n",
       "       3, 0, 2, 1, 1, 2, 2, 2, 3, 3, 0, 2, 0, 1, 2, 2, 0, 2, 3, 1, 0, 0,\n",
       "       0, 0, 2, 0, 2, 3, 2, 2, 3, 2, 1, 2, 0, 3, 0, 3, 1, 1, 0, 1, 1, 2,\n",
       "       1, 0, 2, 2, 3, 1, 1, 2, 1, 0, 2, 3, 1, 2, 3])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ac26d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6ee6dad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        92\n",
      "           1       0.98      1.00      0.99        85\n",
      "           2       1.00      1.00      1.00        95\n",
      "           3       1.00      1.00      1.00        51\n",
      "\n",
      "    accuracy                           0.99       323\n",
      "   macro avg       0.99      0.99      0.99       323\n",
      "weighted avg       0.99      0.99      0.99       323\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "28f8d5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amila Kasun\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('MRI_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5ed538c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('Datathon-Dataset\\category1_tumor\\gt_img (1).jpg')\n",
    "img = cv2.resize(img,(150,150))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8bdbe837",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"MRI_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f3715c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a0f66639",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"mt_img (55).jpg\"  # Replace with the path to your image\n",
    "image = load_img(image_path, target_size=(150, 150))  # Resize to match your model's input size\n",
    "image_array = img_to_array(image)\n",
    " # Normalize pixel values (assuming you did this during training)\n",
    "\n",
    "# Expand dimensions to create a batch of one image\n",
    "image_batch = np.expand_dims(image_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5b09db94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n"
     ]
    }
   ],
   "source": [
    "prediction = loaded_model.predict(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "34621dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a06f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
